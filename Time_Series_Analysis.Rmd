---
title: "COVID-19 Forecast: Gotham City, Fifth Burrough"
author: "Jack Stehn"
date: "5/10/2021"
output:
  bookdown::pdf_document2: 
                toc: false
---

```{r setup, include=FALSE}
library(ggplot2)
library(gridExtra)
library(grid)
library(lattice)
library(forecast)
library(astsa)

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r}
sarima_wPACF = function (xdata, p, d, q, P = 0, D = 0, Q = 0, S = -1, details = TRUE, 
          xreg = NULL, Model = TRUE, fixed = NULL, tol = sqrt(.Machine$double.eps), 
          no.constant = FALSE, max.lag = -1) 
{
  layout = graphics::layout
  par = graphics::par
  plot = graphics::plot
  grid = graphics::grid
  title = graphics::title
  polygon = graphics::polygon
  abline = graphics::abline
  lines = graphics::lines
  frequency = stats::frequency
  coef = stats::coef
  dnorm = stats::dnorm
  ppoints = stats::ppoints
  qnorm = stats::qnorm
  time = stats::time
  na.pass = stats::na.pass
  trans = ifelse(is.null(fixed), TRUE, FALSE)
  trc = ifelse(details, 1, 0)
  n = length(xdata)
  if (is.null(xreg)) {
    constant = 1:n
    xmean = rep(1, n)
    if (no.constant == TRUE) 
      xmean = NULL
    if (d == 0 & D == 0) {
      fitit = stats::arima(xdata, order = c(p, d, q), seasonal = list(order = c(P, 
                                                                                D, Q), period = S), xreg = xmean, include.mean = FALSE, 
                           fixed = fixed, trans = trans, optim.control = list(trace = trc, 
                                                                              REPORT = 1, reltol = tol))
    }
    else if (xor(d == 1, D == 1) & no.constant == FALSE) {
      fitit = stats::arima(xdata, order = c(p, d, q), seasonal = list(order = c(P, 
                                                                                D, Q), period = S), xreg = constant, fixed = fixed, 
                           trans = trans, optim.control = list(trace = trc, 
                                                               REPORT = 1, reltol = tol))
    }
    else fitit = stats::arima(xdata, order = c(p, d, q), 
                              seasonal = list(order = c(P, D, Q), period = S), 
                              include.mean = !no.constant, fixed = fixed, trans = trans, 
                              optim.control = list(trace = trc, REPORT = 1, reltol = tol))
  }
  if (!is.null(xreg)) {
    fitit = stats::arima(xdata, order = c(p, d, q), seasonal = list(order = c(P, 
                                                                              D, Q), period = S), xreg = xreg, fixed = fixed, trans = trans, 
                         optim.control = list(trace = trc, REPORT = 1, reltol = tol))
  }
  if (details) {
    old.par <- par(no.readonly = TRUE)
    layout(matrix(c(1, 2, 4, 1, 3, 5), ncol = 2))
    par(mar = c(2.2, 2, 1, 0.25) + 0.5, mgp = c(1.6, 0.6, 
                                                0))
    
    ## Standardized residuals
    
    rs <- fitit$residuals
    stdres <- rs/sqrt(fitit$sigma2)
    num <- sum(!is.na(rs))
    plot.ts(stdres, main = "Standardized Residuals", ylab = "")
    if (Model) {
      if (S < 0) {
        title(paste("Model: (", p, ",", d, ",", q, ")", 
                    sep = ""), adj = 0)
      }
      else {
        title(paste("Model: (", p, ",", d, ",", q, ") ", 
                    "(", P, ",", D, ",", Q, ") [", S, "]", sep = ""), 
              adj = 0)
      }
    }
    
    ## ACF
    
    alag <- max(10 + sqrt(num), 3 * S, max.lag)
    ACF = stats::acf(rs, alag, plot = FALSE, na.action = na.pass)$acf[-1]
    LAG = 1:alag/frequency(xdata)
    L = 2/sqrt(num)
    plot(LAG, ACF, type = "h"
         , ylim = c(min(ACF) - 0.1, min(1,  max(ACF + 0.4)))
         , main = "ACF of Residuals")
    abline(h = c(0, -L, L), lty = c(1, 2, 2), col = c(1,4, 4))
    
    ## Q-Q Plot
    
    stats::qqnorm(stdres, main = "Normal Q-Q Plot of Std Residuals")
    sR <- !is.na(stdres)
    ord <- order(stdres[sR])
    ord.stdres <- stdres[sR][ord]
    PP <- stats::ppoints(num)
    z <- stats::qnorm(PP)
    y <- stats::quantile(ord.stdres, c(0.25, 0.75), names = FALSE, 
                         type = 7, na.rm = TRUE)
    x <- stats::qnorm(c(0.25, 0.75))
    b <- diff(y)/diff(x)
    a <- y[1L] - b * x[1L]
    abline(a, b, col = 4)
    SE <- (b/dnorm(z)) * sqrt(PP * (1 - PP)/num)
    qqfit <- a + b * z
    U <- qqfit + 3.9 * SE
    L <- qqfit - 3.9 * SE
    z[1] = z[1] - 0.1
    z[length(z)] = z[length(z)] + 0.1
    xx <- c(z, rev(z))
    yy <- c(L, rev(U))
    polygon(xx, yy, border = NA, col = gray(0.6, alpha = 0.2))
    
    
    ## PACF
    
    alag <- max(10 + sqrt(num), 3 * S, max.lag)
    PACF = stats::pacf(rs, alag, plot = FALSE, na.action = na.pass)$acf
    LAG = 1:alag/frequency(xdata)
    L = 2/sqrt(num)
    plot(LAG, PACF, type = "h", ylim = c(min(PACF) - 0.1, min(1,max(PACF + 0.4))), 
         main = "PACF of Residuals")
    abline(h = c(0, -L, L), lty = c(1, 2, 2), col = c(1,4, 4))
    
    
    ##?
    
    nlag <- ifelse(S < 7, 20, 3 * S)
    ppq <- p + q + P + Q - sum(!is.na(fixed))
    if (nlag < ppq + 8) {
      nlag = ppq + 8
    }
    pval <- numeric(nlag)
    for (i in (ppq + 1):nlag) {
      u <- stats::Box.test(rs, i, type = "Ljung-Box")$statistic
      pval[i] <- stats::pchisq(u, i - ppq, lower.tail = FALSE)
    }
    plot((ppq + 1):nlag, pval[(ppq + 1):nlag], xlab = "LAG (H)", 
         ylab = "p value", ylim = c(-0.1, 1), main = "p values for Ljung-Box statistic")
    abline(h = 0.05, lty = 2, col = "blue")
    on.exit(par(old.par))
  }
  if (is.null(fixed)) {
    coefs = fitit$coef
  }
  else {
    coefs = fitit$coef[is.na(fixed)]
  }
  dfree = fitit$nobs - length(coefs)
  t.value = coefs/sqrt(diag(fitit$var.coef))
  p.two = stats::pf(t.value^2, df1 = 1, df2 = dfree, lower.tail = FALSE)
  ttable = cbind(Estimate = coefs, SE = sqrt(diag(fitit$var.coef)), 
                 t.value, p.value = p.two)
  ttable = round(ttable, 4)
  k = length(coefs)
  n = n - (d + D)
  BIC = stats::BIC(fitit)/n
  AIC = stats::AIC(fitit)/n
  AICc = (n * AIC + ((2 * k^2 + 2 * k)/(n - k - 1)))/n
  list(fit = fitit, degrees_of_freedom = dfree, ttable = ttable, 
       AIC = AIC, AICc = AICc, BIC = BIC)
}
```


# Executive Summary
With resources running low, Gotham City needs predictions of new cases for the next ten days in each burrough so it can strategically allocate aid. COVID-19 cases in the fifth burrough of Gotham City are expected to remain high. A differencing model (Specified by a first difference and a lag 7 difference) with ARMA(2,1)x(0,2)[7] noise was used to forecast cases. It appears the recent wave has already peaked and flattened.

# Exploratory Data Analysis

The data on COVID-19 cases started in April 2020. It shows a overall upward trend that has flattened out. It also has two major waves peaking in late July and late January as demonstrated in the left panel of Figure \@ref(fig:EDA). There is a strong weekly seasonal pattern as demonstrated in the right panel of Figure \@ref(fig:EDA). This is likely reflective of testing practices rather than the actual spread of the virus. Also of note is that the data is heteroscedastic with variance linked to mean.


```{r EDA, fig.cap="Daily COVID-19 Cases. In the right panel, red and blue circles denote Mondays and Thursdays respectively", fig.height = 3, fig.width=8, out.width = "90%", fig.align = 'center'}

covid = read.csv(file = "data/data_covid.csv", header = TRUE)
covid$date = as.Date(covid$date, format = "%m/%d/%y")
covid$weekdays = factor(weekdays(covid$date), levels=weekdays(covid$date)[1:7])
covid$holiday = tis::isHoliday(covid$date, businessOnly=FALSE)
covid$post_holiday = tis::isHoliday(covid$date-1, businessOnly=FALSE)


c = (ggplot(covid, aes(date,cases))
     + geom_line()
     + ggtitle("COVID-19 Cases")
     + xlab("Date") + ylab("Cases")
     + scale_y_continuous(labels = scales::comma)
     + scale_x_date(date_breaks = "1 month",
                    date_minor_breaks = "1 week",
                    date_labels = "%b"))



jul_oct = subset(covid, date >= "2020-07-01" & date < "2020-10-01")

weekends = (ggplot()
     + geom_line(jul_oct, mapping=aes(date,cases))
     + ggtitle("Cases Jul to Oct")
     + xlab("Date") + ylab("Cases")
     + scale_y_continuous(labels = scales::comma)
     + scale_x_date(date_breaks = "1 month",
                    date_minor_breaks = "1 week",
                    date_labels = "%b")
     +  geom_point(data=jul_oct[jul_oct$weekdays == "Monday",],
                   mapping=aes(date, cases), color="red", size=5, shape="o")
     +  geom_point(data=jul_oct[jul_oct$weekdays == "Thursday",],
                   mapping=aes(date, cases), color="blue", size=5, shape="o")
     )

grid.arrange(c, weekends, nrow = 1)
```

When looking closer, there are also a few peculiar days in the dataset. Some days have 0 cases and the following day has a massive spike in cases. It can be assumed that this is due to a failure to report cases on those particular days and the number of cases is the result of both date's COVID-19 cases being combined. This requires imputation of those values for two reasons: To use a variance stabilizing transformation and to create a better model that more accurately reflects reality. The imputation on these dates was done as follows:

$$p := \frac{\left(\frac{cases_{t-7}}{cases_{t-7}+cases_{t-7+1}}+\frac{cases_{t+7}}{cases_{t+7}+cases_{t+7+1}}\right)}{2}$$
$$cases'_t = p\cdot cases_{t+1},\,\,\, cases'_{t+1} = (1-p)\cdot cases_{t+1}$$

This imputation was made with a few assumptions.  That 0 cases on day $t$ indicate there were no tests reported that day rather than having exactly 0 cases. Cases that would have appeared on day $t$ are counted on day $t+1$, so the total cases on day $t+1$ should be preserved and spread between the two days. The proportion of cases between $t$ and $t+1$ is similar to the proportions of nearby weeks. 

A final observation to note is that there appears to be a drop in the number of cases reported on holidays and the day following a holiday relative to what we may normally expect on those days. Both the imputed values and holidays have been marked in Figure \@ref(fig:imputation).

For the analysis, a log transform is used to stabilize the data. The variance seems much more stable on the log scale as shown in Figure \@ref(fig:imputation).


```{r}
blank_dates <- which(covid$cases == 0)
ratio = ((covid$cases[blank_dates-7]/(covid$cases[blank_dates-7]+covid$cases[blank_dates-7+1])
          +covid$cases[blank_dates-7]/(covid$cases[blank_dates+7]+covid$cases[blank_dates+7+1]))
         /2)

covid$cases[blank_dates] = covid$cases[blank_dates+1] * ratio
covid$cases[blank_dates+1] = covid$cases[blank_dates+1] * (1 - ratio)
```


```{r imputation, fig.cap="COVID-19 Case date on log scale with Imputed Values (Blue Circles) and Holidays (Orange Circles)", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center'}

covid$log_cases = log(covid$cases)

c = (ggplot()
     + geom_line(data=covid, aes(date,cases))
     + geom_point(aes(x=covid$date[blank_dates],y=covid$cases[blank_dates]),
                  color="blue", shape="o", size=5)
     + geom_point(aes(x=covid$date[covid$holiday], y=covid$cases[covid$holiday]), color="#CC5500", shape="o", size=5)
     #+ geom_point(aes(x=covid$date[covid$post_holiday], y=covid$cases[covid$post_holiday]), color="red")
     + ggtitle("COVID-19 Cases with Marked Imputed Values and Holidays")
     + xlab("Date") + ylab("Cases")
     + scale_y_continuous(labels = scales::comma, trans="log10")
     + scale_x_date(date_breaks = "1 month",
                    date_minor_breaks = "1 week",
                    date_labels = "%b"))

c
```


```{r log, message=FALSE, fig.cap="COVID-19 cases on a log scale", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center', include=FALSE}
pgram = function(x){
  m = floor(length(x)/2)
  pgram = abs(fft(x)[2:(m+1)])^2/length(x)
  plot(pgram, type = "h")
  abline(h=0)
  return(pgram)
}
#p_gram = pgram(covid$log_cases)
#print(which(p_gram>10))
vst_c = (ggplot(data=covid, mapping=aes(date, cases))
         + geom_line()
         + ylab("Cases")
         + xlab("Date")
         + ggtitle('Cases (log scale)')
         + scale_y_continuous(trans="log10"))
vst_c
```

# Models Considered

To model the natural signal in this data, both a parametric model and a differencing approach are used. Both of these models of the signal will be complimented with ARMA models for the remaining noise.

## Parametric Signal Model

First, a parametric model is considered. For the base model, a degree 2 polynomial was used based on time. The waves that in the data are approximately represented by a 6 month period, so we created a sinusoid with that period and interacted that feature. To capture the weekly seasonality, indicators for each week day were used in this model. Finally indicator variables for whether the date was a holiday or a following day were added to the linear model. This is deterministic signal model is detailed in Equation \@ref(eq:param) below, where $X_t$ is the additive noise term.


\begin{align}
\log(cases_t) =&\, \beta_0 + \beta_1 t + \beta_2 t^2+ \sum_{j=1}^6 \beta_{2+j}tI_{\text{weekday}_{jt}} \nonumber \\&
+ \beta_9 t I_{\text{holiday}_{t}} + \beta_{10} t I_{\text{day after holiday}_{t}} \nonumber \\&
+ \beta_{11} t \cos\left(\frac{2\pi t}{6*30.5}\right) + \beta_{12} t\sin\left(\frac{2\pi t}{6*30.5}\right)  + X_t
(\#eq:param)
\end{align}



```{r polyfit, message=FALSE, fig.cap="The parametric signal model. Left shows of fitted parametric model (orange), observed values (grey), and predicted values (blue) and the right panel shows the residuals of the model.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center'}
## Parametric fit
#d = 7
#week_cos_1 = cos(2*pi*time*1/d); week_sin_1 = sin(2*pi*time*1/d)
#week_cos_2 = cos(2*pi*time*2/d); week_sin_2 = sin(2*pi*time*2/d)
#week_cos_3 = cos(2*pi*time*3/d); week_sin_3 = sin(2*pi*time*3/d)

d = 6*30.5
covid$season_cos_1 = cos(2*pi*covid$ID*1/d)
covid$season_sin_1 = sin(2*pi*covid$ID*1/d)
#covid$season_cos_2 = cos(2*pi*time*2/d); covid$season_sin_2 = sin(2*pi*time*2/d)
#covid$season_cos_3 = cos(2*pi*time*3/d); covid$season_sin_3 = sin(2*pi*time*3/d)

model_parametric = lm(log_cases ~ poly(ID, degree=2)
                      + weekdays * ID
                      #+ week_cos_1 * ID + week_sin_1 * ID
                      #+ week_cos_2 * ID + week_sin_2 * ID
                      #+ week_cos_3 * time + week_sin_3 * time
                      + season_cos_1 * ID + season_sin_1 * ID
                      + holiday * ID
                      + post_holiday * ID
                      #+ season_cos_2 * ID + season_sin_2 * ID
                      #+ season_cos_3 + season_sin_3
                      , data = covid
                      )

future_dates = seq(tail(covid$date,1), tail(covid$date,1) + 1 + 14, by="day")
future_ids = (tail(covid$ID,1)):(tail(covid$ID,1) + length(future_dates) - 1)
future_cos_week_1 = cos(2*pi*future_ids*1/7)
future_sin_week_1 = sin(2*pi*future_ids*1/7)
future_cos_week_2 = cos(2*pi*future_ids*2/7)
future_sin_week_2 = sin(2*pi*future_ids*2/7)
future_holidays = tis::isHoliday(future_dates, businessOnly=FALSE)
future_post_holidays = tis::isHoliday(future_dates+1, businessOnly=FALSE)

predict_data <- data.frame(
  ID = future_ids,
  weekdays = weekdays(future_dates),
  season_cos_1 = cos(2*pi*future_ids*1/d),
  season_sin_1 = sin(2*pi*future_ids*1/d),
  week_cos_1 = cos(2*pi*future_ids*1/7),
  week_sin_1 = sin(2*pi*future_ids*1/7),
  week_cos_2 = cos(2*pi*future_ids*2/7),
  week_sin_2 = sin(2*pi*future_ids*2/7),
  holiday = future_holidays,
  post_holiday = future_post_holidays
)


model_df = rbind(cbind(stack(data.frame(Observed = covid$log_cases,
                                        Fitted = fitted(model_parametric))), x=rep(covid$ID,2)),
                 data.frame(ind="Prediction",
                            values=predict(model_parametric, newdata=predict_data),
                            x=predict_data$ID))
plot_model = (ggplot(data=model_df)
              + geom_line(mapping=aes(x, values, color=ind))
              + labs(col = "Legend")
              + theme(legend.position = "none")
              + xlab(paste("Days Since", format(head(covid$date), format="%b %d %Y")))
              + ylab("Log(cases)")
              + ggtitle("Observed Cases vs. Model w/ Prediction")
              + scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))
              )
para_resid = (ggplot()
              + geom_line(aes(x=covid$ID, y=model_parametric$residuals))
              + xlab(paste("Days Since", format(head(covid$date), format="%b %d %Y")))
              + ylab ("Residuals")
              + ggtitle("Residuals"))
grid.arrange(plot_model, para_resid, nrow = 1)
```

Figure \@ref(fig:polyfit) presents the fit as well as the residuals, which appear to be reasonably stationary. It also includes the predicted trend for 10 days to verify that the result is a reasonable trend.



### Parametric Signal with AR(1)

The autocorrelation function (ACF) and partial autocorrelation function (PACF) plots for the parametric model residuals are shown in Figure \@ref(fig:acf1). The PACF plot appears to have 1 significant value at lag 1. Furthermore, the ACF of appears to follow an exponential decrease with significant values only in the beginning. This immediately suggests an AR model. These two observations lead to proposing $p=1$ as a potential fit. In Figure \@ref(fig:acf1), marked with orange circles, we see the theoretical ACF of the fitted $AR(1)$ model. It decays very quickly, however it is not an unreasonable match.

### Parametric Signal with AR(3)

In the PACF plot of \@ref(fig:acf1), there is a significant value at lag 1 and the lags at 2 and 3 are possibly not significant. They are also close enough to significance that to warrant investigation. These observations suggest an AR model with $p=3$ as a different potential fit. The theoretical ACF values of this model are marked by purple circles. It is a much better match with values closer to sample ACF and PACF. The tradeoff is that it is a more complicated model.


```{r s11, results='hide', message=FALSE, fig.cap="Diagnostic plots for Auto Regressive p=1 (AR(1)) model on parametric model's residuals.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center', include='false'}
#Diagnostic plots for AR(1) model on parametric model's residuals.
s1.1 = sarima_wPACF(model_parametric$residuals, d=0, p=1, q=0)

```


```{r}
phi_1 <- getElement(s1.1$fit$coef,"ar1")
acf_s11 <- ARMAacf(ar=phi_1,lag.max=50)
pacf_s11 <- ARMAacf(ar=phi_1,lag.max=50,pacf=TRUE)
```



```{r s12, results='hide', message=FALSE, fig.cap="Diagnostic plots for AR(3) model on parametric model's residuals.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center', include='false'}
#Diagnostic plots for AR(3) model on parametric model's residuals.
s1.2 <- sarima_wPACF(model_parametric$residuals,p=3,d=0,q=0)

phi_1 <- getElement(s1.2$fit$coef,"ar1")
phi_2 <- getElement(s1.2$fit$coef,"ar2")
phi_3 <- getElement(s1.2$fit$coef,"ar3")
acf_s12 <- ARMAacf(ar=c(phi_1,phi_2,phi_3),lag.max=50)
pacf_s12 <- ARMAacf(ar=c(phi_1,phi_2,phi_3),lag.max=50, pacf=TRUE)
```

```{r acf1, fig.cap="ACF/PACF of parametric model residuals with theoretical values of fitted AR(1) and AR(3) models. Sample ACF and PACF are shown with black lines.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center'}
par(mfrow=c(1,2))
acf(model_parametric$residuals, main="ACF of Residuals", lag.max=25)
points(0:25-0.02,acf_s11[1:26], col="#CC5500")
points(0:25+0.02,acf_s12[1:26], col="purple")
legend("topright", legend=c("AR(1)", "AR(3)"),
       col=c("#CC5500", "blue"), pch=1, cex=0.8)

pacf(model_parametric$residuals, main="PACF of Residuals", pacf=TRUE, lag.max=25)
points(1:25-0.02,pacf_s11[1:25], col="#CC5500")
points(1:25+0.02,pacf_s12[1:25], col="purple")
legend("topright", legend=c("AR(1)", "AR(3)"),
       col=c("#CC5500", "blue"), pch=1, cex=0.8)
```


## Differencing

As previously addressed, there is a locally linear trend of cases and weekly seasonality. While there are two waves of COVID-19 cases, it also appears to be locally linear. To address both of these things, a first difference and lag-7 difference are used. This is written as  $\nabla_7\nabla Cases$. The implied model is shown in the left panel of Figure \@ref(fig:differencing). The right panel shows the time series of the differences, which appear stationary. Again, to address heteroscedasticity, a log-transform was preformed.



```{r differencing, message=FALSE, fig.cap="Diagnostics for differencing model. The left panel shows data in black and the fitted values in orange. The right plot shows the differenced time series.", fig.height = 3.75, fig.width=8, out.width = "90%", fig.align = 'center'}
covid$log_cases = log(covid$cases)
differenced = diff(diff(covid$log_cases), lag=7)
covid$impliedmodel = NA
for(i in 9:nrow(covid)){
        covid$impliedmodel[i] = mean(differenced) + covid$log_cases[i-1] + covid$log_cases[i-7] - covid$log_cases[i-1-7]
}
diff_plot = (ggplot(covid)
        + geom_line(mapping=aes(date, log_cases), color="#999999", lwd=.725)
        + geom_line(mapping=aes(date, impliedmodel), color="#E69F00")
        + xlab("Date")
        + ylab ("Log Cases")
        + ggtitle("Differencing Fitted Model"))

diff_resid = (ggplot()
              + geom_line(aes(x=covid$date[9:nrow(covid)],y=differenced))
              + xlab("Date")
              + ylab ("Log Cases")
              + ggtitle(expression(paste(nabla[7],nabla,"log(Cases)"[t]))))

grid.arrange(diff_plot, diff_resid, nrow = 1)

```

### Differencing with ARMA(2,1)x(0,2)[7]

The Autocorrelation function (ACF) and partial autocorrelation function (PACF) plots for the differenced model are shown in Figure \@ref(fig:acf2). In the ACF plot, we can see significant values in multiples of 7, suggesting a seasonal ARMA model with S=7. There are no clear cutoffs values for these seasonal ACF and PACF values suggesting a multiplicative SARMA model is necessary and the cutoff rules for determining  parameters cannot be used.

Significant values at every seventh lag of the PACF plot and 2 seasonal significant value in the ACF plot suggest that Q=2 and S=7. Following these peaks, there is a decaying PACF which suggests an positive value of q. There is also two significant values in the PACF, which suggests a p=2. With experimentation, a plausible model with p=2, q=1, Q=2 with S=7. The theoretical values of this fitted MSARMA(2,1)x(0,2)[7] the ACF and PACF are shown in figure \@ref(fig:acf2) marked by orange circles.


```{r s21, results='hide', message=FALSE, fig.cap="Diagnostic plots for ARMA(2,1)x(0,2)[7] model on differencing model.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center', include='false'}
s2.1 = sarima_wPACF(covid$log_cases, p=2, d=1, q=1, P=0, D=1, Q=2, S=7)

```

### Differencing with ARMA(2,2)x(3,1)[7]

In an alternative interpretation a significant value at 7 in the ACF plot and 3 possible seasonal significant values in the PACF plot suggest that P=3, Q=1, and S=7. Following these peaks, there is a decaying PACF which suggests an positive value of q. There is also two significant values in the PACF, which suggests a p=2. Together, with expirimentation, this gives us p=2, q=2, P=3, Q=1 with S=7. The theoretical ACF/PACF of the fitted model is demonstrated in figure \@ref(fig:acf2). The purple circles fit the peaks significant values in the sample ACF/PACF.

```{r s22, results='hide', message=FALSE, fig.cap="Diagnostic plots for ARMA(2,2)x(3,1)[7] model on differencing model.", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center', include='false'}
s2.2 = sarima_wPACF(covid$log_cases, p=2, d=1, q=2, P=3, D=1, Q=1, S=7)
```

```{r}
phi_1 = getElement(s2.1$fit$coef, "ar1")
phi_2 = getElement(s2.1$fit$coef, "ar2")

ar <- c(phi_1,phi_2)

theta_1 = getElement(s2.1$fit$coef, "ma1")
Theta_1 = getElement(s2.1$fit$coef, "sma1")
Theta_2 = getElement(s2.1$fit$coef, "sma2")

ma <- c(theta_1, 0,0,0,0,0,Theta_1, Theta_1*theta_1, 0,0,0,0,0, Theta_2, Theta_2*theta_1)

acf_s21 = ARMAacf(ar=ar, ma=ma, lag.max=50)
pacf_s21 = ARMAacf(ar=ar, ma=ma, lag.max=50, pacf=TRUE)

phi_1 = getElement(s2.2$fit$coef, "ar1")
phi_2 = getElement(s2.2$fit$coef, "ar2")
Phi_1 = getElement(s2.2$fit$coef, "sar1")
Phi_2 = getElement(s2.2$fit$coef, "sar2")
Phi_3 = getElement(s2.2$fit$coef, "sar3")

theta_1 = getElement(s2.2$fit$coef, "ma1")
theta_2 = getElement(s2.2$fit$coef, "ma2")
Theta_1 = getElement(s2.2$fit$coef, "sma1")

ar=c(phi_1, phi_2, 0, 0, 0, 0, Phi_1, -phi_1*Phi_2, -Phi_1*phi_2,
          0,0,0,0,
          Phi_2, -phi_1*Phi_2, -phi_2*Phi_2, 0,0,0,0,
          Phi_3, -Phi_3*phi_1, -phi_2*Phi_3)

ma=c(theta_1, theta_2, 0,0,0,0,Theta_1, theta_1*Theta_1, theta_2*Theta_1)

acf_s22 = ARMAacf(ar=ar, ma=ma, lag.max=50)
pacf_s22 = ARMAacf(ar=ar, ma=ma, lag.max=50, pacf=TRUE)
```

```{r acf2, fig.cap="ACF/PACF of differencing model residuals with theoretical values of fitted ARMA models", fig.height = 4, fig.width=8, out.width = "90%", fig.align = 'center'}
par(mfrow=c(1,2))
acf(differenced, main="ACF of Residuals")
points(0:50-0.02,acf_s21, col="#CC5500")
points(0:50+0.02,acf_s22, col="blue")
legend("topright", legend=c("ARMA(2,1)X(0,2)[7]", "ARMA(2,2)X(3,1)[7]"),
       col=c("#CC5500", "blue"), pch=1, cex=0.8)

pacf(differenced, main="PACF of Residuals", pacf=TRUE, lag.max=25)
points(1:50-0.02,pacf_s21, col="#CC5500")
points(1:50+0.02,pacf_s22, col="blue")
```


# Model Comparison and Selection

```{r cross_valid}
sum_squared_errors <- c(model1.1=0, model1.2=0, model2.1=0, model2.2=0)
rows = nrow(covid)
d = 6*30.5
covid$differenced[seq(nrow(covid)-length(differenced)+1,nrow(covid))] = differenced

for (i in 1:10) {
  train_set <- subset(covid, ID<=(rows-10*i))
  test_set <- subset(covid, ID>(rows-10*i) & ID<=rows-10*(i-1))$cases
  
  mod1.signal = lm(log_cases ~ poly(ID, degree=2)
                      + weekdays * ID
                      + season_cos_1 * ID + season_sin_1 * ID
                      + holiday * ID
                      + post_holiday * ID
                      , data = train_set
                      )
  future_dates = seq(tail(train_set$date,1)+1, tail(train_set$date,1) + 10, by="day")
  future_ids = seq(tail(train_set$ID,1)+1, tail(train_set$ID,1)+10)
  future_holidays = tis::isHoliday(future_dates, businessOnly=FALSE)
  future_post_holidays = tis::isHoliday(future_dates+1, businessOnly=FALSE)
  
  predict_data <- data.frame(
    ID = future_ids,
    weekdays = weekdays(future_dates),
    season_cos_1 = cos(2*pi*future_ids*1/d),
    season_sin_1 = sin(2*pi*future_ids*1/d),
    holiday = future_holidays,
    post_holiday = future_post_holidays
  )
  
  mod1.signal.forecast = predict(mod1.signal, newdata=predict_data)
  mod1.arma1.pred = exp(sarima.for(mod1.signal$residuals, n.ahead=10, p=1, d=0, q=0, plot=FALSE)$pred)
  mod1.arma2.pred = exp(sarima.for(mod1.signal$residuals, n.ahead=10, p=3, d=0, q=0, plot=FALSE)$pred)
  
  mod1.pred1 = as.numeric(mod1.signal.forecast+mod1.arma1.pred)
  mod1.pred2 = as.numeric(mod1.signal.forecast+mod1.arma2.pred)
  sum_squared_errors["model1.1"] = sum_squared_errors["model1.1"]+ sum((test_set - mod1.pred1)^2)
  sum_squared_errors["model1.2"] = sum_squared_errors["model1.2"]+ sum((test_set - mod1.pred2)^2)
  #plot(seq(1,nrow(train_set)), train_set$log_cases, type="l", xlim=c(1,tail(train_set$ID,1)+10))
  #lines(future_ids, mod1.pred1, col="blue")
  
  mod2.arma1 = arima(train_set$log_cases, order=c(2,1,1), seasonal=list(order=c(0,1,2), period=7), method="CSS")
  mod2.arma2 = arima(train_set$log_cases, order=c(2,1,2), seasonal=list(order=c(3,1,1), period=7), method="CSS")
  
  mod2.pred1 = exp(predict(mod2.arma1,n.ahead=10)$pred)
  mod2.pred2 = exp(predict(mod2.arma2,n.ahead=10)$pred)
  
  sum_squared_errors["model2.1"] = sum_squared_errors["model2.1"] + sum((test_set - mod2.pred1)^2)
  sum_squared_errors["model2.2"] = sum_squared_errors["model2.2"] + sum((test_set - mod2.pred2)^2)
  
}

RMSPE = sqrt(sum_squared_errors/100)
```

These four model options are compared through time series cross validation on the log-transformed data set. The nonoverlapping testing sets rolled through the last 100 days in the data, 10/17/2020 through 01/24/2021, in 10 day segments. Thus there will be 100 forecasted points over these 10 windows. The training sets consist of all data that occur before the appropriate testing set. The models' forecasting performances will be compared through root-mean-square prediction error (RMSPE). The model with the lowest RMSPE will be chosen as the model for predicting COVID-19 cases over the next 10 days.

Table \@ref(tab:rmsetable) shows that the differenced model with ARMA(2,1)x(0,2)[7] has the lowest cross-validated prediction error with ARMA(2,2)x(3,1)[7] as a close second. Thus the differenced ARMA(2,1)x(0,2)[7] is chosen as the forecasting model. 

```{r rmsetable}
#RMSE table
rmse = matrix(sqrt(sum_squared_errors/100), nrow=4,ncol = 1)
colnames(rmse) = "RMSPE"
rownames(rmse) = c(
        "Parametric Model + AR(1)",
        "Parametric Model + AR(3)",
        "Daily Differencing + Weekly Differencing + ARMA(2,1)x(0,2)[7]",
        "Daily Differencing + Weekly Differencing + ARMA(2,2)x(3,1)[7]"
        )
knitr::kable(rmse,caption = "Cross-validated root mean squared prediction error for the four models under consideration.")
```

# Results

To forecast cases in the next 10 days (01/25/21 to 02/03/21), a model with differences at lag 7 and lag 1 will be used for the signal and augmented with an ARMA(2,1)x(0,2)[7] process for the noise. Let $Cases_t$ be the number of cases at day $t$ with an noise term $X_t$. $X_t$ is a stationary process with 0 mean defined by ARMA(2,1)X(0,2)[7], $W_t$ is white noise with variance $\sigma^2_W$. This can be compactly written as ARIMA(2,1,1)x(0,1,2)[7]. The model can be represented as in Equation \@ref(eq:final). $\phi_i, \Theta_i, \theta_i$ are all estimated in the next Appendix 1 Table 2. Note that $\Theta_1$ and $\theta_1$ have large magnitude with a negative with very tight bounds for the standard error.  This suggests that $X_t$ is highly dependent on the white noise term $W_{t-7}$ and $W_{t-1}$.


\begin{align}
log(Cases_{t}) =& \log(Cases_{t-1}) + \log(Cases_{t-7}) - \log(Cases_{t-8}) + X_t \nonumber \\
X_t =& \phi X_{t-1} + \phi_2 X_{t-2} + W_t + \theta_1 W_{t-1} + \Theta_1 W_{t-7} + \theta_1\Theta_1 W_{t-8} + \Theta_2 W_{t-14} + \theta_1\Theta_2 W_{t-15}
(\#eq:final)
\end{align}

## Prediction

Figure \@ref(fig:pred) shows the forecasted values of COVID-19 cases for the next ten days. It appears the recent wave has already peaked and flattened. Notably, the prediction for upcoming cases have high variance is cause for concern. This indicates that a rise in cases is not the expected outcome, but it is not probable.


```{r pred, fig.cap="Forecasts of COVID-19 Cases in the fifth burrough of Gotham City from 01/25/21 to 02/03/21. The grey bands indicate the Â±2 standard errors.", fig.height = 3.5, fig.width=8, out.width = "90%", fig.align = 'center'}
observed.dates = covid$date
observed.cases = covid$cases
predicted.model = sarima.for(covid$log_cases, p=2, d=1, q=1, P=0, D=1, Q=2, S=7, n.ahead=10, plot=FALSE)
predicted.dates = seq(tail(covid$date,1)+1, by=1, length.out=10)
predicted.cases = exp(predicted.model$pred)
predicted.ucb = exp(predicted.model$pred + 2*(predicted.model$se))
predicted.lcb = exp(predicted.model$pred - 2*(predicted.model$se))

plot_predict = (ggplot()
               + geom_line(mapping=aes(observed.dates, observed.cases))
               + geom_point(mapping=aes(observed.dates, observed.cases),
                            shape=1)
               + geom_line(mapping=aes(predicted.dates, predicted.cases),
                           col="red")
               + geom_point(mapping=aes(predicted.dates, predicted.cases),
                            shape=1, col="red")
               + geom_line(mapping=aes(predicted.dates, predicted.ucb),
                           col="#999999")
               + geom_line(mapping=aes(predicted.dates, predicted.lcb),
                           col="#999999")
               + scale_x_date(date_breaks = "1 month",
                    date_minor_breaks = "1 week",
                    date_labels = "%b",
                    lim=c(min(observed.dates)+150, max(predicted.dates)))
               + scale_y_continuous(labels=scales::comma, lim=c(0,max(predicted.ucb)))
               + ggtitle("COVID-19 Case Forecast")
               + xlab("Date")
               + ylab("Cases")
               )

plot_predict

# plot(tail(append(observed.dates,predicted.dates),200),
#      tail(append(observed.cases, rep(NA, length(predicted.dates))),200),
#      ylim=c(min(covid$cases), max(predicted.ucb)), type = "l")
# lines(predicted.dates, predicted.cases, col="blue")
# lines(predicted.dates, predicted.ucb, col="#999999")
# lines(predicted.dates, predicted.lcb, col="#999999")
```


\newpage
# Appendix 1 - Table of Parameter Estimates for ARIMA(2,1,0)x(1,1,2)[7]

Table 2: Estimates of the forecasting model parameters in Equation \@ref(eq:final) with their standard errors (SE). Note that this model includes a seasonal difference at lag 7 and a first difference.

|Parameter|Estimate|SE
|:---------|---:|---:|
|	$\phi_1$			|	0.2591  	|	0.0874
|	$\phi_2$			|	-0.0167  	|	0.0720   
|	$\theta_1$			|	-0.7672	|	0.0695
|	$\Theta_1$			|	-0.7805	|	0.0672
|	$\Theta_2$			|	-0.0546	|	0.0695
|	$\sigma^2_W$			|	0.060	|	


